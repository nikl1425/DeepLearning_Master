{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHB MIT DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load edf data\n",
    "2. define class sz/nsz\n",
    "3. insert class cols\n",
    "4. concat\n",
    "5. windowing\n",
    "6. ensemple learn resnet152, inceptionv3, incep+resnet\n",
    "7. define OHEM loss\n",
    "8. build network\n",
    "9. evaluate\n",
    "10. calculate for confussion matrices (f1-score etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.5.0\n",
      "Keras Version: 2.5.0\n",
      "\n",
      "Python 3.9.7 (default, Sep 16 2021, 23:53:23) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.3.1\n",
      "Scikit-Learn 0.24.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import mne\n",
    "import pathlib\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "import os\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/niklashjort/Desktop/Notes/Speciale/projects'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "FREQ = 256\n",
    "database_path = 'Dataset/CHB-MIT/chb-mit-scalp-eeg-database-1.0.0/'\n",
    "filtered_database_path = 'Dataset/CHB-MIT/Filtered-chb-mit/'\n",
    "filted_db_parquet_path = \"Dataset/CHB-MIT/dataframe-parquet\"\n",
    "edf_file_type = \".edf\"\n",
    "patient_one_path = 'chb04/'\n",
    "summary_txt_file_type = \"-summary.txt\"\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_patient_folder_names(database_path):\n",
    "    folders = os.listdir(database_path)\n",
    "    patient_folder_names = [(database_path + \"/\" + x) for x in folders if (x.find(\".DS_Store\") == -1)]\n",
    "    return patient_folder_names\n",
    "\n",
    "def get_all_file_names(directory):\n",
    "    files = os.listdir(directory)\n",
    "    edfFileNameList = [(directory + \"/\" + x) for x in files if (x.endswith(edf_file_type))]\n",
    "    summary_info_file_name = [(directory + \"/\" + x) for x in files if (x.endswith(summary_txt_file_type))]\n",
    "    return (summary_info_file_name[0], edfFileNameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary file name: Dataset/CHB-MIT/Filtered-chb-mit//chb20/chb20-summary.txt edf file name: Dataset/CHB-MIT/Filtered-chb-mit//chb20/chb20_59.edf\n"
     ]
    }
   ],
   "source": [
    "# Testing:\n",
    "summary_file_path, edf_file_paths = get_all_file_names(get_all_patient_folder_names(filtered_database_path)[0])\n",
    "\n",
    "print(f\"summary file name: {summary_file_path} edf file name: {edf_file_paths[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadEdfFile(FileName, print_reader_info = False):\n",
    "    try:\n",
    "        if(print_reader_info):\n",
    "            data = mne.io.read_raw_edf(FileName)\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw\n",
    "        else:\n",
    "            data = mne.io.read_raw_edf(FileName, verbose='error')\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw\n",
    "    except:\n",
    "        print(\"error: something went wrong with edf-reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1-F7</th>\n",
       "      <th>F7-T7</th>\n",
       "      <th>T7-P7</th>\n",
       "      <th>P7-O1</th>\n",
       "      <th>.-0</th>\n",
       "      <th>FP1-F3</th>\n",
       "      <th>F3-C3</th>\n",
       "      <th>C3-P3</th>\n",
       "      <th>P3-O1</th>\n",
       "      <th>.-1</th>\n",
       "      <th>...</th>\n",
       "      <th>FP2-F8</th>\n",
       "      <th>F8-T8</th>\n",
       "      <th>T8-P8</th>\n",
       "      <th>P8-O2</th>\n",
       "      <th>.-4</th>\n",
       "      <th>P7-T7</th>\n",
       "      <th>T7-FT9</th>\n",
       "      <th>FT9-FT10</th>\n",
       "      <th>FT10-T8</th>\n",
       "      <th>STI 014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.919414e-05</td>\n",
       "      <td>6.388278e-05</td>\n",
       "      <td>-3.809524e-05</td>\n",
       "      <td>-4.825397e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>8.400488e-06</td>\n",
       "      <td>5.489621e-05</td>\n",
       "      <td>-3.711844e-06</td>\n",
       "      <td>-2.285714e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738706e-05</td>\n",
       "      <td>4.004884e-05</td>\n",
       "      <td>-2.793651e-05</td>\n",
       "      <td>-5.919414e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>3.848596e-05</td>\n",
       "      <td>-3.711844e-06</td>\n",
       "      <td>-1.113553e-05</td>\n",
       "      <td>-1.894994e-05</td>\n",
       "      <td>131045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.758242e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.367521e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>9.768010e-07</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.758242e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.367521e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>-1.758242e-06</td>\n",
       "      <td>3.321123e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FP1-F7         F7-T7         T7-P7         P7-O1           .-0  \\\n",
       "0  5.919414e-05  6.388278e-05 -3.809524e-05 -4.825397e-05  1.953602e-07   \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07  5.860806e-07  1.953602e-07   \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.758242e-06  1.953602e-07   \n",
       "4  1.953602e-07  5.860806e-07  1.953602e-07 -1.758242e-06  1.953602e-07   \n",
       "\n",
       "         FP1-F3         F3-C3         C3-P3         P3-O1           .-1  ...  \\\n",
       "0  8.400488e-06  5.489621e-05 -3.711844e-06 -2.285714e-05  1.953602e-07  ...   \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  ...   \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07  5.860806e-07  1.953602e-07  ...   \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.367521e-06  1.953602e-07  ...   \n",
       "4  1.953602e-07  1.953602e-07  1.953602e-07 -1.367521e-06  1.953602e-07  ...   \n",
       "\n",
       "         FP2-F8         F8-T8         T8-P8         P8-O2           .-4  \\\n",
       "0  1.738706e-05  4.004884e-05 -2.793651e-05 -5.919414e-05  1.953602e-07   \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "4  1.953602e-07  5.860806e-07  1.953602e-07 -1.953602e-07  1.953602e-07   \n",
       "\n",
       "          P7-T7        T7-FT9      FT9-FT10       FT10-T8   STI 014  \n",
       "0  3.848596e-05 -3.711844e-06 -1.113553e-05 -1.894994e-05  131045.0  \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07       0.0  \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07 -1.953602e-07       0.0  \n",
       "3  1.953602e-07  5.860806e-07  9.768010e-07 -9.768010e-07       0.0  \n",
       "4  1.953602e-07 -9.768010e-07 -1.758242e-06  3.321123e-06       0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing \n",
    "test_df = ReadEdfFile(edf_file_paths[8], print_reader_info=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage & Loading Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edf files takes a lot of memory (look below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.71 MB\n"
     ]
    }
   ],
   "source": [
    "# print(test_df.info(memory_usage='deep'))\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "print(mem_usage(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add col ['timems', class] - Reduce dtypes - Compress + Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.parquet.FastParquetImpl"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.io.parquet.get_engine('auto').__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dtypes, save memory, uptimize loading times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    _start = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    int_cols = [c for c in df if df[c].dtype in ['int64', 'int32']]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    _end = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    saved_time = (_start - _end) / _start * 100\n",
    "    #print(f\"Saved: {saved_time:.2f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing:\n",
    "test_df = downcast_dtypes(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert time ms in dataframe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_format_info_file(txt_summary_file_path):\n",
    "    str_container = \"\"\n",
    "    with open(txt_summary_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            str_container += str(line).replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    formatted_str = re.findall('<br><br>(.*?)<br><br>', str_container)\n",
    "\n",
    "    for index, line in enumerate(formatted_str):\n",
    "        if re.match('(^Channels in EDF Files:|^Channels changed:)', line):\n",
    "            formatted_str.remove(formatted_str[index])\n",
    "        else:\n",
    "            pass\n",
    "    return formatted_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 line: File Name: chb20_02.edf<br>File Start Time: 17:55:44<br>File End Time: 18:55:44<br>Number of Seizures in File: 0\n",
      "index: 1 line: File Name: chb20_04.edf<br>File Start Time: 19:55:59<br>File End Time: 20:55:59<br>Number of Seizures in File: 0\n",
      "index: 2 line: File Name: chb20_06.edf<br>File Start Time: 21:56:13<br>File End Time: 22:56:13<br>Number of Seizures in File: 0\n",
      "index: 3 line: File Name: chb20_08.edf<br>File Start Time: 23:56:26<br>File End Time: 24:56:26<br>Number of Seizures in File: 0\n",
      "index: 4 line: File Name: chb20_12.edf<br>File Start Time: 03:56:53<br>File End Time: 4:56:53<br>Number of Seizures in File: 1<br>Seizure 1 Start Time: 94 seconds<br>Seizure 1 End Time: 123 seconds\n",
      "index: 5 line: File Name: chb20_14.edf<br>File Start Time: 05:57:07<br>File End Time: 6:57:07<br>Number of Seizures in File: 1<br>Seizure 1 Start Time: 1971 seconds<br>Seizure 1 End Time: 2009 seconds\n",
      "index: 6 line: File Name: chb20_16.edf<br>File Start Time: 07:57:20<br>File End Time: 8:55:09<br>Number of Seizures in File: 1<br>Seizure 1 Start Time: 2226 seconds<br>Seizure 1 End Time: 2261 seconds\n",
      "index: 7 line: File Name: chb20_21.edf<br>File Start Time: 12:51:27<br>File End Time: 13:51:45<br>Number of Seizures in File: 0\n",
      "index: 8 line: File Name: chb20_23.edf<br>File Start Time: 14:11:44<br>File End Time: 15:01:08<br>Number of Seizures in File: 0\n",
      "index: 9 line: File Name: chb20_26.edf<br>File Start Time: 17:05:27<br>File End Time: 18:05:27<br>Number of Seizures in File: 0\n",
      "index: 10 line: File Name: chb20_28.edf<br>File Start Time: 19:05:40<br>File End Time: 20:05:40<br>Number of Seizures in File: 0\n",
      "index: 11 line: File Name: chb20_30.edf<br>File Start Time: 21:05:54<br>File End Time: 22:05:54<br>Number of Seizures in File: 0\n",
      "index: 12 line: File Name: chb20_34.edf<br>File Start Time: 01:06:21<br>File End Time: 2:06:21<br>Number of Seizures in File: 0\n",
      "index: 13 line: File Name: chb20_60.edf<br>File Start Time: 01:44:11<br>File End Time: 2:44:11<br>Number of Seizures in File: 0\n"
     ]
    }
   ],
   "source": [
    "# Testing:\n",
    "for index, obj in enumerate(read_format_info_file(summary_file_path)):\n",
    "    print(f\"index: {index} line: {obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sz information for [patient]-summary.txt files. </br>\n",
    "Then get information on seizures timestamp and the file name </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileInformationContainer:\n",
    "    def __init__(self, information_str):\n",
    "        self.information_str = self.clean_string(information_str)\n",
    "        self.file_name = self.set_filename()\n",
    "        self.time_start = self.set_file_time_start_ms()\n",
    "        self.sz_info = self.set_sz_information()\n",
    "        \n",
    "    def clean_string(self, uncleaned_str):\n",
    "        return uncleaned_str.replace(\"<br>\", \" \")\n",
    "\n",
    "    def set_filename(self):\n",
    "        filename_found = re.match(r\"^File Name: (.+?).edf\", self.information_str)\n",
    "        if filename_found:\n",
    "            return filename_found.group(1)\n",
    "        else:\n",
    "            print(f\"{self.file_name} failed get_filename\")\n",
    "            return \"filename not found\"\n",
    "    \n",
    "    def get_milli_sec(self, time_str):\n",
    "        \"\"\"Get Seconds from time.\"\"\"\n",
    "        h, m, s = time_str.split(':')\n",
    "        return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000\n",
    "\n",
    "    def set_file_time_start_ms(self):\n",
    "        time_start_found = re.match(r\".*File Start Time: (.*?) File\", self.information_str)\n",
    "        if time_start_found:\n",
    "            try:\n",
    "                return self.get_milli_sec(time_start_found.group(1))\n",
    "            except Exception as e :\n",
    "                print(f\"{self.file_name}: error {e} cannot convert to ms time\")\n",
    "                return f\"{e}\"\n",
    "        else:\n",
    "            print(f\"{self.file_name} failed get_file_time_start_ms\")\n",
    "            return \"time start not found\"\n",
    "    \n",
    "    def get_sz_count(self):\n",
    "        sz_count = 0\n",
    "        count_found = re.search(r\".*Seizures in File: (.*?) Seizure\", self.information_str)\n",
    "        if count_found:\n",
    "            sz_count = count_found.group(1)\n",
    "        if int(sz_count) > 0:\n",
    "            return int(sz_count)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "    def set_sz_information(self):\n",
    "        if(type(self.get_sz_count()) != None and self.get_sz_count() > 0):\n",
    "            try:\n",
    "                pattern = re.compile(r\"Seizure [1-9] (?P<state>[?:Start|End]+) Time: (?P<Sec>[0-9]+)\")\n",
    "                myList = [m.groupdict() for m in pattern.finditer(self.information_str)]\n",
    "                for item in myList:\n",
    "                    converted_time = int(item.get(\"Sec\")) * 1000\n",
    "                    item[\"Sec\"] = converted_time\n",
    "                formatted = []\n",
    "                for i in range(0, len(myList), 2):\n",
    "                    formatted.append({\"sz_start\" : myList[i][\"Sec\"], \"sz_end\" : myList[i+1][\"Sec\"]})\n",
    "                return formatted\n",
    "            except Exception as e:\n",
    "                print(f\"set_sz_information failed at file: {self.file_name} with the following exception: {e}\")\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def get(self):\n",
    "        return self.information_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object with sz \n",
      " info-str: File Name: chb20_04.edf File Start Time: 19:55:59 File End Time: 20:55:59 Number of Seizures in File: 0\n",
      " file-name: chb20_04\n",
      " time-start: 71759000\n",
      " sz-information: [] \n",
      "\n",
      "-------------------------------------\n",
      "Object with sz \n",
      " info-str: File Name: chb20_12.edf File Start Time: 03:56:53 File End Time: 4:56:53 Number of Seizures in File: 1 Seizure 1 Start Time: 94 seconds Seizure 1 End Time: 123 seconds\n",
      " file-name: chb20_12\n",
      " time-start: 14213000\n",
      " sz-information: [{'sz_start': 94000, 'sz_end': 123000}]\n"
     ]
    }
   ],
   "source": [
    "# Testing:\n",
    "w_no_sz_str = FileInformationContainer(read_format_info_file(summary_file_path)[1])\n",
    "print(f\"Object with sz \\n info-str: {w_no_sz_str.information_str}\\n file-name: {w_no_sz_str.file_name}\\n time-start: {w_no_sz_str.time_start}\\n sz-information: {w_no_sz_str.sz_info} \\n\")\n",
    "print(\"-------------------------------------\")\n",
    "w_sz_str = FileInformationContainer(read_format_info_file(summary_file_path)[4])\n",
    "print(f\"Object with sz \\n info-str: {w_sz_str.information_str}\\n file-name: {w_sz_str.file_name}\\n time-start: {w_sz_str.time_start}\\n sz-information: {w_sz_str.sz_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chb20_12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14213000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Test object:\n",
    "obj = FileInformationContainer(read_format_info_file(summary_file_path)[4])\n",
    "print(obj.file_name)\n",
    "obj.time_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert timestamp in files based of freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_time_stamp(dataframe, file_start_time):\n",
    "    period_row_increment_value =  (1 / 256) * 1000\n",
    "    dataframe.insert(0, \"timestamp\", [file_start_time + i * period_row_increment_value for i in dataframe.index])\n",
    "\n",
    "    \n",
    "insert_time_stamp(test_df, obj.time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>FP1-F7</th>\n",
       "      <th>F7-T7</th>\n",
       "      <th>T7-P7</th>\n",
       "      <th>P7-O1</th>\n",
       "      <th>.-0</th>\n",
       "      <th>FP1-F3</th>\n",
       "      <th>F3-C3</th>\n",
       "      <th>C3-P3</th>\n",
       "      <th>P3-O1</th>\n",
       "      <th>...</th>\n",
       "      <th>FP2-F8</th>\n",
       "      <th>F8-T8</th>\n",
       "      <th>T8-P8</th>\n",
       "      <th>P8-O2</th>\n",
       "      <th>.-4</th>\n",
       "      <th>P7-T7</th>\n",
       "      <th>T7-FT9</th>\n",
       "      <th>FT9-FT10</th>\n",
       "      <th>FT10-T8</th>\n",
       "      <th>STI 014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.864000e+07</td>\n",
       "      <td>1.387057e-05</td>\n",
       "      <td>-3.692308e-05</td>\n",
       "      <td>-4.493284e-06</td>\n",
       "      <td>-2.930403e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>2.324786e-05</td>\n",
       "      <td>-5.919414e-05</td>\n",
       "      <td>6.661782e-05</td>\n",
       "      <td>-6.114774e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.402930e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.333333e-05</td>\n",
       "      <td>2.520147e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>4.884005e-06</td>\n",
       "      <td>-7.619048e-06</td>\n",
       "      <td>-4.395604e-05</td>\n",
       "      <td>6.075702e-05</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.864000e+07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.864001e+07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.864001e+07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.864002e+07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>-1.758242e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.758242e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>-3.321123e-06</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>4.102564e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp        FP1-F7         F7-T7         T7-P7         P7-O1  \\\n",
       "0  2.864000e+07  1.387057e-05 -3.692308e-05 -4.493284e-06 -2.930403e-06   \n",
       "1  2.864000e+07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2  2.864001e+07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "3  2.864001e+07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "4  2.864002e+07  1.953602e-07  1.953602e-07 -1.953602e-07 -1.758242e-06   \n",
       "\n",
       "            .-0        FP1-F3         F3-C3         C3-P3         P3-O1  ...  \\\n",
       "0  1.953602e-07  2.324786e-05 -5.919414e-05  6.661782e-05 -6.114774e-05  ...   \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  ...   \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  ...   \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  5.860806e-07  ...   \n",
       "4  1.953602e-07  1.953602e-07 -5.860806e-07  1.953602e-07 -1.758242e-06  ...   \n",
       "\n",
       "         FP2-F8         F8-T8         T8-P8         P8-O2           .-4  \\\n",
       "0 -2.402930e-05  1.953602e-07  5.333333e-05  2.520147e-05  1.953602e-07   \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "4 -1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "\n",
       "          P7-T7        T7-FT9      FT9-FT10       FT10-T8  STI 014  \n",
       "0  4.884005e-06 -7.619048e-06 -4.395604e-05  6.075702e-05     53.0  \n",
       "1  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07      0.0  \n",
       "2  1.953602e-07  1.953602e-07  1.953602e-07 -1.953602e-07      0.0  \n",
       "3  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07      0.0  \n",
       "4  5.860806e-07 -3.321123e-06 -1.953602e-07  4.102564e-06      0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing:\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert class column based on the below frow paper: </br>\n",
    "Interictal = normal state </br>\n",
    "Preictal I = 30 min. before sz </br>\n",
    "Preictal II = 10 min. before sz </br>\n",
    "Seizure = sz_start -> sz_end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_class_col(dataframe, sz_info_list):\n",
    "    \n",
    "    if \"class\" not in dataframe.columns:\n",
    "        dataframe.insert(0, \"class\", np.nan)\n",
    "\n",
    "    if len(sz_info_list) == 0:\n",
    "        dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal I\") & (dataframe['class'] != \"Preictal II\"), \"class\"] = \"Interictal\"\n",
    "    else:\n",
    "        for item in sz_info_list:\n",
    "            sz_start = item[\"sz_start\"]\n",
    "            sz_end = item[\"sz_end\"]\n",
    "            actual_sz_start = dataframe.iloc[0]['timestamp'] + sz_start\n",
    "            preictal_one_start = actual_sz_start - (30 * 60 * 1000)\n",
    "            preictal_two_start = actual_sz_start - (10 * 60 * 1000)\n",
    "            \n",
    "            actual_sz_end = actual_sz_start + sz_end\n",
    "            #print(f\"sz: {sz_start} end: {sz_end} prei1: {preictal_one_start} prei2: {preictal_two_start} actsz: {actual_sz_start} actend: {actual_sz_end}\")\n",
    "            \n",
    "            dataframe['timestamp'] = pd.to_numeric(dataframe['timestamp'])\n",
    "\n",
    "            #INSERTING INTERICTAL\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal I\") & (dataframe['class'] != \"Preictal II\") & (dataframe['timestamp'] > actual_sz_end) | (dataframe['timestamp'] < preictal_one_start), \"class\"] = \"Interictal\"\n",
    "\n",
    "            #INSERTING PREICTAL I\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['timestamp'] >= preictal_one_start) & (dataframe['timestamp'] < preictal_two_start), \"class\"] = \"Preictal I\"\n",
    "\n",
    "            #INSERTING PREICTAL II\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['timestamp'] >= preictal_two_start) & (dataframe['timestamp'] < actual_sz_start), \"class\"] = \"Preictal II\"\n",
    "\n",
    "            #INSERTING SEIZURE CLASS\n",
    "            dataframe.loc[(dataframe['timestamp'] >= actual_sz_start) & (dataframe['timestamp'] <= actual_sz_end), \"class\"] = \"seizure\"\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df.drop(columns=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: chb20_16 sz_count: 1 sz_start: 2226000 sz_end: 2261000\n",
      "[{'sz_start': 2226000, 'sz_end': 2261000}]\n",
      "inside\n",
      "inside3\n",
      "sz: 2226000 end: 2261000 prei1: 29066000.0 prei2: 30266000.0 actsz: 30866000.0 actend: 33127000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "seizure        318208\n",
       "Preictal I     307200\n",
       "Preictal II    153600\n",
       "Interictal     109056\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing:\n",
    "filename = obj.file_name\n",
    "count = obj.get_sz_count()\n",
    "start = obj.sz_info[0][\"sz_start\"]\n",
    "end = obj.sz_info[0][\"sz_end\"]\n",
    "print(f\"filename: {filename} sz_count: {count} sz_start: {start} sz_end: {end}\")\n",
    "insert_class_col(test_df, obj.sz_info)\n",
    "test_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing \"Preictal I\" because seizure is very early from file time start..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_save_compress(path, patient, filename, df):\n",
    "    df.to_parquet(f\"{path}{patient}{filename}.parquet.gzip\", compression=\"gzip\")\n",
    "# Exampled\n",
    "# df_save_compress(database_path, patient_one_path, \"filename\", ch01_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load all files in paper. </br> 2. For each directory (patient) extract file information to object.</br> 3. Downcast datatypes. </br>4. Insert class and timestamp cols.</br> 5.Compress and save."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying and saving all dataframes to parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seizure        417024\n",
      "Preictal I     307200\n",
      "Preictal II    153600\n",
      "Interictal      43776\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for patient in get_all_patient_folder_names(filtered_database_path)[0:1]:\n",
    "    current_patient = patient\n",
    "    info_txt_path, edf_files = get_all_file_names(current_patient)\n",
    "\n",
    "    # read & extract information\n",
    "    info_txt = read_format_info_file(info_txt_path)\n",
    "    \n",
    "    for line in info_txt[5:6]:\n",
    "        edf_info_container = FileInformationContainer(line)\n",
    "        selected_edf_path = [x for x in edf_files if (edf_info_container.file_name in x)][0]\n",
    "        edf_df = ReadEdfFile(selected_edf_path)\n",
    "        edf_df = downcast_dtypes(edf_df)\n",
    "        insert_time_stamp(edf_df, edf_info_container.time_start)\n",
    "        insert_class_col(edf_df, edf_info_container.sz_info)\n",
    "        print(edf_df['class'].value_counts())\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read & load compressed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/CHB-MIT/chb-mit-scalp-eeg-database-1.0.0/chb04/chb20_16.parquet.gzip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-55f2891c63e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcompressed_file_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".parquet.gzip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompressed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpatient_one_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcompressed_file_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             handles = get_handle(\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/CHB-MIT/chb-mit-scalp-eeg-database-1.0.0/chb04/chb20_16.parquet.gzip'"
     ]
    }
   ],
   "source": [
    "compressed_file_type = \".parquet.gzip\"\n",
    "compressed_df = pd.read_parquet(database_path + patient_one_path + filename + compressed_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(compressed_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36ba892f7ad20bf7fdc5c3ef3188feda3b9d9c608c682b5345226fde4f33924b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
