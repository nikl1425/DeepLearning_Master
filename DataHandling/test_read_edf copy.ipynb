{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Tensor Flow Version: 2.5.0\n",
      "Keras Version: 2.5.0\n",
      "\n",
      "Python 3.9.7 (default, Sep 16 2021, 23:53:23) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.3.1\n",
      "Scikit-Learn 0.24.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import mne\n",
    "import pathlib\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "import os\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "#pd.io.parquet.get_engine('auto').__class__\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/niklashjort/Desktop/Notes/Speciale/projects/DataHandling'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "FREQ = 256\n",
    "database_path = 'Dataset/CHB-MIT/chb-mit-scalp-eeg-database-1.0.0/'\n",
    "filtered_database_path = '../Dataset/CHB-MIT/Filtered-chb-mit/'\n",
    "filted_db_parquet_path = \"Dataset/CHB-MIT/dataframe-parquet\"\n",
    "edf_file_type = \".edf\"\n",
    "patient_one_path = 'chb04/'\n",
    "summary_txt_file_type = \"-summary.txt\"\n",
    "external_hardisk_drive_path = os.path.dirname('/Volumes/LaCie/Database/')\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get file paths and info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_patient_folder_names(database_path):\n",
    "    folders = os.listdir(database_path)\n",
    "    patient_folder_names = [(database_path + \"/\" + x) for x in folders if (x.find(\".DS_Store\") == -1)]\n",
    "    return patient_folder_names\n",
    "\n",
    "def get_all_file_names(directory):\n",
    "    files = os.listdir(directory)\n",
    "    edfFileNameList = [(directory + \"/\" + x) for x in files if (x.endswith(edf_file_type))]\n",
    "    summary_info_file_name = [(directory + \"/\" + x) for x in files if (x.endswith(summary_txt_file_type))]\n",
    "    return (summary_info_file_name[0], edfFileNameList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read EDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadEdfFile(FileName, print_reader_info = False):\n",
    "    try:\n",
    "        if(print_reader_info):\n",
    "            data = mne.io.read_raw_edf(FileName)\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw\n",
    "        else:\n",
    "            data = mne.io.read_raw_edf(FileName, verbose='error')\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from ../Dataset/CHB-MIT/Filtered-chb-mit/chb10/chb10_12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "x = mne.io.read_raw_edf(filtered_database_path + \"chb10/chb10_12.edf\")\n",
    "y = ReadEdfFile(filtered_database_path + \"chb10/chb10_12.edf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_df.info(memory_usage='deep'))\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    _start = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    int_cols = [c for c in df if df[c].dtype in ['int64', 'int32']]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    _end = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    saved_time = (_start - _end) / _start * 100\n",
    "    #print(f\"Saved: {saved_time:.2f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format summary txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_format_info_file(txt_summary_file_path):\n",
    "    str_container = \"\"\n",
    "    with open(txt_summary_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            str_container += str(line).replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    formatted_str = re.findall('(.*?)<br><br>', str_container)\n",
    "    bla = [x.group() for x in re.finditer('(.*?)<br><br>', str_container)]\n",
    "    for index, line in enumerate(formatted_str):\n",
    "        if re.match('(^Channels in EDF Files:|^Channels changed:)', line):\n",
    "            formatted_str.remove(formatted_str[index])\n",
    "        else:\n",
    "            pass\n",
    "    return formatted_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileInformationContainer:\n",
    "    def __init__(self, information_str):\n",
    "        self.information_str = self.clean_string(information_str)\n",
    "        self.file_name = self.set_filename()\n",
    "        self.time_start = self.set_file_time_start_ms()\n",
    "        self.sz_info = self.set_sz_information()\n",
    "        \n",
    "    def clean_string(self, uncleaned_str):\n",
    "        return uncleaned_str.replace(\"<br>\", \" \")\n",
    "\n",
    "    def set_filename(self):\n",
    "        filename_found = re.match(r\"^File Name: (.+?).edf\", self.information_str)\n",
    "        if filename_found:\n",
    "            return filename_found.group(1)\n",
    "        else:\n",
    "            print(f\"{self.file_name} failed get_filename\")\n",
    "            return \"filename not found\"\n",
    "    \n",
    "    def get_milli_sec(self, time_str):\n",
    "        \"\"\"Get Seconds from time.\"\"\"\n",
    "        dt_obj = datetime.strptime(time_str,'%H:%M:%S')\n",
    "        millisec = dt_obj.timestamp() * 1000\n",
    "        return millisec\n",
    "\n",
    "    def set_file_time_start_ms(self):\n",
    "        time_start_found = re.match(r\".*File Start Time: (.*?) File\", self.information_str)\n",
    "        if time_start_found:\n",
    "            try:\n",
    "                return self.get_milli_sec(time_start_found.group(1))\n",
    "            except Exception as e :\n",
    "                print(f\"{self.file_name}: error {e} cannot convert to ms time\")\n",
    "                return f\"{e}\"\n",
    "        else:\n",
    "            print(f\"{self.file_name} failed get_file_time_start_ms\")\n",
    "            return \"time start not found\"\n",
    "    \n",
    "    def get_sz_count(self):\n",
    "        sz_count = 0\n",
    "        count_found = re.search(r\".*Seizures in File: (.*?) Seizure\", self.information_str)\n",
    "        if count_found:\n",
    "            sz_count = count_found.group(1)\n",
    "        if int(sz_count) > 0:\n",
    "            return int(sz_count)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "    def set_sz_information(self):\n",
    "        if(type(self.get_sz_count()) != None and self.get_sz_count() > 0):\n",
    "            try:\n",
    "                pattern = re.compile(r\"Seizure [1-9] (?P<state>[?:Start|End]+) Time: (?P<Sec>[0-9]+)\")\n",
    "                myList = [m.groupdict() for m in pattern.finditer(self.information_str)]\n",
    "                if(len(myList) <= 0):\n",
    "                     pattern = re.compile(r\"Seizure (?P<state>[?:Start|End]+) Time: (?P<Sec>[0-9]+)\")\n",
    "                     myList = [m.groupdict() for m in pattern.finditer(self.information_str)]\n",
    "                for item in myList:\n",
    "                    converted_time = int(item.get(\"Sec\")) * 1000\n",
    "                    item[\"Sec\"] = converted_time\n",
    "                formatted = []\n",
    "                for i in range(0, len(myList), 2):\n",
    "                    formatted.append({\"sz_start\" : myList[i][\"Sec\"], \"sz_end\" : myList[i+1][\"Sec\"]})\n",
    "                return formatted\n",
    "            except Exception as e:\n",
    "                print(f\"set_sz_information failed at file: {self.file_name} with the following exception: {e}\")\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def get(self):\n",
    "        return self.information_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_time_stamp(dataframe, file_start_time):\n",
    "    period_row_increment_value =  (1 / 256) * 1000\n",
    "    dataframe.insert(0, \"timestamp\", [file_start_time + i * period_row_increment_value for i in dataframe.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_class_col(dataframe, sz_info_list):\n",
    "    \n",
    "    if \"class\" not in dataframe.columns:\n",
    "        dataframe.insert(0, \"class\", np.nan)\n",
    "\n",
    "    if len(sz_info_list) == 0:\n",
    "        dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal I\") & (dataframe['class'] != \"Preictal II\"), \"class\"] = \"Interictal\"\n",
    "    else:\n",
    "        for item in sz_info_list:\n",
    "            sz_start = item[\"sz_start\"]\n",
    "            sz_end = item[\"sz_end\"]\n",
    "            #print(f\"hihi: {dataframe.iloc[0]['timestamp']}\")\n",
    "            actual_sz_start = dataframe.iloc[0]['timestamp'] + sz_start\n",
    "            preictal_one_start = actual_sz_start - (30 * 60 * 1000)\n",
    "            preictal_two_start = actual_sz_start - (10 * 60 * 1000)\n",
    "            actual_sz_end = dataframe.iloc[0]['timestamp'] + sz_end\n",
    "            dataframe['timestamp'] = pd.to_numeric(dataframe['timestamp'])\n",
    "\n",
    "            # #INSERTING INTERICTAL\n",
    "            # dataframe.loc[(dataframe['class'] != \"seizure\") | (dataframe['class'] != \"Preictal I\") | (dataframe['class'] != \"Preictal II\") | (dataframe['timestamp'] > actual_sz_end) | (dataframe['timestamp'] < actual_sz_start), \"class\"] = \"Interictal\"\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal II\") & (dataframe['class'] != \"Preictal I\"), \"class\"] = \"Interictal\"\n",
    "\n",
    "            #INSERTING PREICTAL I\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal II\")  & (dataframe['timestamp'] >= preictal_one_start) & (dataframe['timestamp'] < preictal_two_start), \"class\"] = \"Preictal I\"\n",
    "\n",
    "            #INSERTING PREICTAL II\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['timestamp'] >= preictal_two_start) & (dataframe['timestamp'] < actual_sz_start), \"class\"] = \"Preictal II\"\n",
    "\n",
    "            #INSERTING SEIZURE CLASS\n",
    "            dataframe.loc[(dataframe['timestamp'] >= actual_sz_start) & (dataframe['timestamp'] < actual_sz_end), \"class\"] = \"seizure\"\n",
    "\n",
    "            #print(dataframe[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_save_compress(filename, df):\n",
    "    df.to_csv(f\"{filename}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Dataset/CHB-MIT/Filtered-chb-mit//chb20\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_01.edf File Start Time: 16:55:08 File End Time: 17:55:14 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208931492000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_02.edf File Start Time: 17:55:44 File End Time: 18:55:44 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208927856000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_03.edf File Start Time: 18:55:51 File End Time: 19:55:51 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208924249000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_04.edf File Start Time: 19:55:59 File End Time: 20:55:59 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208920641000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_05.edf File Start Time: 20:56:06 File End Time: 21:56:06 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208917034000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_06.edf File Start Time: 21:56:13 File End Time: 22:56:13 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208913427000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_07.edf File Start Time: 22:56:19 File End Time: 23:56:19 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208909821000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_08.edf File Start Time: 23:56:26 File End Time: 24:56:26 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208906214000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_11.edf File Start Time: 02:56:46 File End Time: 3:56:46 Number of Seizures in File: 0\n",
      "EDF_CONTAINER: ts_start -2208981794000.0\n",
      "EDF_CONTAINER: sz_info []\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_12.edf File Start Time: 03:56:53 File End Time: 4:56:53 Number of Seizures in File: 1 Seizure 1 Start Time: 94 seconds Seizure 1 End Time: 123 seconds\n",
      "EDF_CONTAINER: ts_start -2208978187000.0\n",
      "EDF_CONTAINER: sz_info [{'sz_start': 94000, 'sz_end': 123000}]\n",
      "filename: chb20_12 classes: Interictal     890112\n",
      "Preictal II     24064\n",
      "seizure          7424\n",
      "Name: class, dtype: int64\n",
      "-------------------------------------------------------\n",
      "chb20_12\n",
      "EDF_CONTAINER: info_string passed File Name: chb20_13.edf File Start Time: 04:57:00 File End Time: 5:57:00 Number of Seizures in File: 2 Seizure 1 Start Time: 1440 seconds Seizure 1 End Time: 1470 seconds Seizure 2 Start Time: 2498 seconds Seizure 2 End Time: 2537 seconds\n",
      "EDF_CONTAINER: ts_start -2208974580000.0\n",
      "EDF_CONTAINER: sz_info [{'sz_start': 1440000, 'sz_end': 1470000}, {'sz_start': 2498000, 'sz_end': 2537000}]\n",
      "filename: chb20_13 classes: Preictal I     324608\n",
      "Preictal II    307200\n",
      "Interictal     272128\n",
      "seizure         17664\n",
      "Name: class, dtype: int64\n",
      "-------------------------------------------------------\n",
      "chb20_13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0v/m6wt8rqj7s1dcljdyjrdfxmw0000gn/T/ipykernel_13653/414194162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medf_info_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mdf_save_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medf_info_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medf_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/0v/m6wt8rqj7s1dcljdyjrdfxmw0000gn/T/ipykernel_13653/3868914920.py\u001b[0m in \u001b[0;36mdf_save_compress\u001b[0;34m(filename, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_save_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{filename}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3461\u001b[0m         )\n\u001b[1;32m   3462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3464\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m             )\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         libwriters.write_csv_rows(\n\u001b[1;32m    312\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_format_native_types\u001b[0;34m(self, na_rep, float_format, decimal, quoting, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         return super()._format_native_types(\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_format_native_types\u001b[0;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for patient in get_all_patient_folder_names(filtered_database_path)[0:1]:\n",
    "    print(patient)\n",
    "    current_patient = patient\n",
    "    info_txt_path, edf_files = get_all_file_names(current_patient)\n",
    "    # read & extract information\n",
    "    info_txt = read_format_info_file(info_txt_path)\n",
    "    for line in info_txt[1:]:\n",
    "        #print(line)\n",
    "        edf_info_container = FileInformationContainer(line)\n",
    "        print(f\"EDF_CONTAINER: info_string passed {edf_info_container.information_str}\")\n",
    "        print(f\"EDF_CONTAINER: ts_start {edf_info_container.time_start}\")\n",
    "        print(f\"EDF_CONTAINER: sz_info {edf_info_container.sz_info}\")\n",
    "        selected_edf_path = [x for x in edf_files if (edf_info_container.file_name in x)][0]\n",
    "        edf_df = ReadEdfFile(selected_edf_path)\n",
    "        if edf_info_container.get_sz_count() > 0:\n",
    "            if edf_df is not None:\n",
    "                edf_df = downcast_dtypes(edf_df)\n",
    "                insert_time_stamp(edf_df, edf_info_container.time_start)\n",
    "                #print(f\"info list = {edf_info_container.sz_info}\")\n",
    "                insert_class_col(edf_df, edf_info_container.sz_info)\n",
    "                print(f\"filename: {edf_info_container.file_name} classes: {edf_df['class'].value_counts()}\")\n",
    "                print(\"-------------------------------------------------------\")\n",
    "                print(edf_info_container.file_name)\n",
    "                df_save_compress(edf_info_container.file_name, edf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['File Name: chb20_12.edf<br>File Start Time: 03:56:53<br>File End Time: 4:56:53<br>Number of Seizures in File: 1<br>Seizure 1 Start Time: 94 seconds<br>Seizure 1 End Time: 123 seconds']\n",
      "14213000\n",
      "INFORMATION: File Name: chb20_12.edf File Start Time: 03:56:53 File End Time: 4:56:53 Number of Seizures in File: 1 Seizure 1 Start Time: 94 seconds Seizure 1 End Time: 123 seconds\n",
      "1\n",
      "info list = [{'sz_start': 94000, 'sz_end': 123000}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class        0\n",
       "timestamp    0\n",
       "FP1-F7       0\n",
       "F7-T7        0\n",
       "T7-P7        0\n",
       "P7-O1        0\n",
       ".-0          0\n",
       "FP1-F3       0\n",
       "F3-C3        0\n",
       "C3-P3        0\n",
       "P3-O1        0\n",
       ".-1          0\n",
       "FZ-CZ        0\n",
       "CZ-PZ        0\n",
       ".-2          0\n",
       "FP2-F4       0\n",
       "F4-C4        0\n",
       "C4-P4        0\n",
       "P4-O2        0\n",
       ".-3          0\n",
       "FP2-F8       0\n",
       "F8-T8        0\n",
       "T8-P8        0\n",
       "P8-O2        0\n",
       ".-4          0\n",
       "P7-T7        0\n",
       "T7-FT9       0\n",
       "FT9-FT10     0\n",
       "FT10-T8      0\n",
       "STI 014      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ReadEdfFile(\"../Dataset/CHB-MIT/Filtered-chb-mit//chb20//chb20_12.edf\")\n",
    "x2 = downcast_dtypes(x)\n",
    "info_txt = read_format_info_file(\"../Dataset/CHB-MIT/Filtered-chb-mit//chb20//chb20-summary.txt\")[10:11]\n",
    "print(info_txt)\n",
    "ex_con = FileInformationContainer(info_txt[0])\n",
    "print(ex_con.time_start)\n",
    "print(\"INFORMATION: \" + ex_con.information_str)\n",
    "print(ex_con.get_sz_count())\n",
    "insert_time_stamp(x, ex_con.time_start)\n",
    "print(f\"info list = {ex_con.sz_info}\")\n",
    "insert_class_col(x, ex_con.sz_info)\n",
    "\n",
    "\n",
    "x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14213000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_milli_sec(time_str):\n",
    "        \"\"\"Get Seconds from time.\"\"\"\n",
    "        h, m, s = time_str.split(':')\n",
    "        return ((int(h) * 3600) + (int(m) * 60) + int(s)) * 1000\n",
    "\n",
    "\n",
    "get_milli_sec(\"03:56:53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14213000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "h, m, s = map(float, \"03:56:53\".split(':'))\n",
    "res2 = timedelta(hours=h, minutes=m, seconds=s).total_seconds() * 1000\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17907000.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "h, m, s = map(float, \"04:58:27\".split(':'))\n",
    "res = timedelta(hours=h, minutes=m, seconds=s).total_seconds() * 1000\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3694000.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res - res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2208978093000.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2208978187000.0 + 94000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1900, 1, 1, 23, 56, 26)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.fromtimestamp(-2208906214000.0/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2208978187000.0\n"
     ]
    }
   ],
   "source": [
    "dt_obj = datetime.strptime('03:56:53',\n",
    "                           '%H:%M:%S')\n",
    "millisec = dt_obj.timestamp() * 1000\n",
    "\n",
    "print(millisec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b84e05540a307b538244af4550d97e316ec86dc0712246a760046706883909fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('speciale_01_01': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
