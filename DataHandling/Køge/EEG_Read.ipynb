{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "Tensor Flow Version: 2.5.0\n",
      "Keras Version: 2.5.0\n",
      "\n",
      "Python 3.9.7 (default, Sep 16 2021, 23:53:23) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.3.1\n",
      "Scikit-Learn 0.24.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import mne\n",
    "import pathlib\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib\n",
    "import random\n",
    "import os\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "plt.ioff()\n",
    "import psutil\n",
    "import gc\n",
    "import glob\n",
    "pd.io.parquet.get_engine('auto').__class__\n",
    "%matplotlib inline\n",
    "matplotlib.use('Qt5Agg')\n",
    "#matplotlib.use('agg')\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/niklashjort/Desktop/Notes/Speciale/projects/DataHandling/KÃ¸ge'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "database_path = '../../Dataset/EMU_monitor(ruc)/'\n",
    "save_csv_path = '../../Dataset/EMU_monitor(ruc)/NHR/'\n",
    "edf_file_type = \".edf\"\n",
    "capitilize_edf_file_type = \".EDF\"\n",
    "bdf_file_type = \".BDF\"\n",
    "patient_one_path = 'chb04/'\n",
    "info_df_path = \"../../Dataset/EMU_monitor(ruc)/Eventlist_RUC.xlsx\"\n",
    "external_hardisk_drive_path = os.path.dirname('/Volumes/LaCie/Database/')\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_excel(info_df_path, sheet_name=\"NHR_EDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientID</th>\n",
       "      <th>time_emu</th>\n",
       "      <th>SeizureID</th>\n",
       "      <th>delay</th>\n",
       "      <th>seizureDuration</th>\n",
       "      <th>fileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>22-05-2019 02:45:22</td>\n",
       "      <td>1</td>\n",
       "      <td>83.000001</td>\n",
       "      <td>56</td>\n",
       "      <td>20190521155643_p4Nat2.sdeeg_converted_.easy_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-22 03:50:49</td>\n",
       "      <td>2</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>20190521155643_p4Nat2.sdeeg_converted_.easy_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-22 05:27:56</td>\n",
       "      <td>3</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>20190521155643_p4Nat2.sdeeg_converted_.easy_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-22 07:07:04</td>\n",
       "      <td>4</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>20190521155643_p4Nat2.sdeeg_converted_.easy_fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-22 07:51:24</td>\n",
       "      <td>5</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>20190521155643_p4Nat2.sdeeg_converted_.easy_fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientID             time_emu  SeizureID      delay  seizureDuration  \\\n",
       "0          4  22-05-2019 02:45:22          1  83.000001               56   \n",
       "1          4  2019-05-22 03:50:49          2  83.000000               53   \n",
       "2          4  2019-05-22 05:27:56          3  81.000000               48   \n",
       "3          4  2019-05-22 07:07:04          4  81.000000               52   \n",
       "4          4  2019-05-22 07:51:24          5  81.000000               53   \n",
       "\n",
       "                                            fileName  \n",
       "0  20190521155643_p4Nat2.sdeeg_converted_.easy_fi...  \n",
       "1  20190521155643_p4Nat2.sdeeg_converted_.easy_fi...  \n",
       "2  20190521155643_p4Nat2.sdeeg_converted_.easy_fi...  \n",
       "3  20190521155643_p4Nat2.sdeeg_converted_.easy_fi...  \n",
       "4  20190521155643_p4Nat2.sdeeg_converted_.easy_fi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in info_df.iterrows():\n",
    "    patient_id = r['patientID']\n",
    "    patient_folder = \"Patient \" + str(patient_id)\n",
    "    EEG_file = r['fileName']\n",
    "    for folder in os.listdir(database_path + \"EEG\"):\n",
    "        if patient_folder == folder and EEG_file != 0:\n",
    "            full_path_patient_file = database_path + f\"EEG/{patient_folder}/{EEG_file}\"\n",
    "            info_df.loc[i, \"fullPath\"] = full_path_patient_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = []\n",
    "\n",
    "for i, r in info_df.iterrows():\n",
    "    patient_id = r['patientID']\n",
    "    patient_file = r['fullPath']\n",
    "    container = {\"ID\": patient_id, \"File\": patient_file}\n",
    "\n",
    "    if container not in info_list:\n",
    "        info_list.append(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 4,\n",
       "  'File': '../../Dataset/EMU_monitor(ruc)/EEG/Patient 4/20190521155643_p4Nat2.sdeeg_converted_.easy_filtered.edf'},\n",
       " {'ID': 4,\n",
       "  'File': '../../Dataset/EMU_monitor(ruc)/EEG/Patient 4/20190522090132_p4dag3.sdeeg_converted_.easy_filtered.edf'},\n",
       " {'ID': 6,\n",
       "  'File': '../../Dataset/EMU_monitor(ruc)/EEG/Patient 6/20190826155114_p6nat1.sdeeg_converted_.easy_filtered.edf'},\n",
       " {'ID': 6,\n",
       "  'File': '../../Dataset/EMU_monitor(ruc)/EEG/Patient 6/20190829094329_p6dag4.sdeeg_converted_.easy_filtered.edf'},\n",
       " {'ID': 24,\n",
       "  'File': '../../Dataset/EMU_monitor(ruc)/EEG/Patient 24/ANONYMOU.BDF'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class container():\n",
    "    def __init__(self, delay, time_emu, duration, id):\n",
    "        self.delay = delay\n",
    "        self.time_emu = time_emu\n",
    "        self.duration = duration\n",
    "        self.id = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 4/20190521155643_p4Nat2.sdeeg_converted_.easy_filtered.edf\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 4/20190522090132_p4dag3.sdeeg_converted_.easy_filtered.edf\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 6/20190826155114_p6nat1.sdeeg_converted_.easy_filtered.edf\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 6/20190829094329_p6dag4.sdeeg_converted_.easy_filtered.edf\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 24/ANONYMOU.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 28/ANONYMOU.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 30/P30_TrackIT.edf\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 21/TRACKIT_R1.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 21/TRACKIT_R2.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 21/TRACKIT_R3.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 21/TRACKIT_R4.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 33/ANONYMOU.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 34/ANONYMOU.BDF\n",
      "../../Dataset/EMU_monitor(ruc)/EEG/Patient 35/ANONYMOU.BDF\n"
     ]
    }
   ],
   "source": [
    "file_sz_info = []\n",
    "\n",
    "for c in info_list:\n",
    "    f = c['File']\n",
    "    p = c['ID']\n",
    "    print(f)\n",
    "    cont_storage = []\n",
    "    sz_count = 0\n",
    "    for i, r in info_df.iterrows():\n",
    "        if f == r['fullPath']:\n",
    "            con = container(delay=r['delay'], time_emu=r['time_emu'], duration=r['seizureDuration'], id=r['SeizureID'])\n",
    "            #cont = {\"delay\": r['delay'], \"time_emu\": r['time_emu'], \"duration\": r['seizureDuration'], \"sz_id\": r['SeizureID']}\n",
    "            cont_storage.append(con)\n",
    "    file_sz_info.append([p, f, cont_storage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadEdfFile(file_name, print_reader_info = False):\n",
    "    if edf_file_type in file_name or capitilize_edf_file_type in file_name:\n",
    "        if(print_reader_info):\n",
    "            data = mne.io.read_raw_edf(file_name)\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            print(data.info)\n",
    "            return converted_raw, data.info\n",
    "        else:\n",
    "            data = mne.io.read_raw_edf(file_name, verbose='error')\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw, data.info\n",
    "    if bdf_file_type in file_name:\n",
    "        if(print_reader_info):\n",
    "            data = mne.io.read_raw_bdf(file_name)\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            print(data.info)\n",
    "            return converted_raw, data.info\n",
    "        else:\n",
    "            data = mne.io.read_raw_edf(file_name, verbose='error')\n",
    "            raw_data = data.get_data()\n",
    "            converted_raw = pd.DataFrame(raw_data.transpose(), columns=data.ch_names)\n",
    "            return converted_raw, data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_ms(date_time):\n",
    "    date_time = str(date_time)\n",
    "    if \"+\" in str(date_time):\n",
    "        date_time = str(date_time).split(\"+\")[0]\n",
    "\n",
    "    try:\n",
    "        timestamp_ms = datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S').timestamp() * 1000\n",
    "    except:\n",
    "        timestamp_ms = datetime.strptime(date_time, '%d-%m-%Y %H:%M:%S').timestamp() * 1000\n",
    "    return timestamp_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_time_stamp(dataframe, file_start_time, frq):\n",
    "    timestamp_ms = convert_date_to_ms(file_start_time)\n",
    "    period_row_increment_value =  (1 / int(frq)) * 1000\n",
    "    dataframe.insert(0, \"timestamp\", [timestamp_ms + i * period_row_increment_value for i in dataframe.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_class_col(dataframe, sz_info_list, freq):\n",
    "    print(f\"modtaget string: {sz_info_list}\")\n",
    "    \n",
    "    if \"class\" not in dataframe.columns:\n",
    "        dataframe.insert(0, \"class\", np.nan)\n",
    "\n",
    "    if len(sz_info_list) == 0:\n",
    "        dataframe.loc[(dataframe['class'] != \"Seizure\") & (dataframe['class'] != \"Preictal I\") & (dataframe['class'] != \"Preictal II\"), \"class\"] = \"Interictal\"\n",
    "    else:\n",
    "        for container in sz_info_list:\n",
    "            delay = container.delay * 1000\n",
    "            duration = container.duration * 1000\n",
    "            sz_start = convert_date_to_ms(container.time_emu) + delay\n",
    "            sz_end = sz_start + duration\n",
    "            print(f\"sz_start index = {sz_start}\")\n",
    "            print(f\"sz_end: {sz_end}\")\n",
    "            preictal_start = sz_start - (15 * 60 * 1000)\n",
    "            dataframe['timestamp'] = pd.to_numeric(dataframe['timestamp'])\n",
    "\n",
    "            #INSERTING PREICTAL\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['timestamp'] >= preictal_start) & (dataframe['timestamp'] < sz_start), \"class\"] = \"Preictal\"\n",
    "\n",
    "            #INSERTING SEIZURE CLASS\n",
    "            dataframe.loc[(dataframe['timestamp'] >= sz_start) & (dataframe['timestamp'] < sz_end), \"class\"] = \"seizure\"\n",
    "\n",
    "            #INSERTING INTERICTAL\n",
    "            dataframe.loc[(dataframe['class'] != \"seizure\") & (dataframe['class'] != \"Preictal\"), \"class\"] = \"Interictal\"\n",
    "\n",
    "            print(dataframe[\"class\"].value_counts())\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_info_txt(csv_file_name, freq, channels):\n",
    "    file_object = open(save_csv_path + \"info.txt\", \"a\")\n",
    "    file_object.write(f\"\\nfilename: {csv_file_name} \\n freq: {freq} \\n channels: {channels} \\n\")\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id: 4\n",
      "file_name: ../../Dataset/EMU_monitor(ruc)/EEG/Patient 4/20190521155643_p4Nat2.sdeeg_converted_.easy_filtered.edf\n",
      "freq: 500.0 meas: 2019-05-21 15:56:43+00:00 channels: ['CH-1', 'CH-2']\n",
      "modtaget string: [<__main__.container object at 0x128432e20>, <__main__.container object at 0x29d1d8ee0>, <__main__.container object at 0x12849d2b0>, <__main__.container object at 0x29b092910>, <__main__.container object at 0x12849ad90>, <__main__.container object at 0x29d1de250>]\n",
      "sz_start index = 1558486005000.0005\n",
      "sz_end: 1558486061000.0005\n",
      "Interictal    31922000\n",
      "Preictal        450000\n",
      "seizure          28000\n",
      "Name: class, dtype: int64\n",
      "sz_start index = 1558489932000.0\n",
      "sz_end: 1558489985000.0\n",
      "Interictal    31445500\n",
      "Preictal        900000\n",
      "seizure          54500\n",
      "Name: class, dtype: int64\n",
      "sz_start index = 1558495757000.0\n",
      "sz_end: 1558495805000.0\n",
      "Interictal    30971500\n",
      "Preictal       1350000\n",
      "seizure          78500\n",
      "Name: class, dtype: int64\n",
      "sz_start index = 1558501705000.0\n",
      "sz_end: 1558501757000.0\n",
      "Interictal    30495500\n",
      "Preictal       1800000\n",
      "seizure         104500\n",
      "Name: class, dtype: int64\n",
      "sz_start index = 1558504365000.0\n",
      "sz_end: 1558504418000.0\n",
      "Interictal    30019000\n",
      "Preictal       2250000\n",
      "seizure         131000\n",
      "Name: class, dtype: int64\n",
      "sz_start index = 1558505702000.0\n",
      "sz_end: 1558505756000.0\n",
      "Interictal    29542000\n",
      "Preictal       2700000\n",
      "seizure         158000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for e in file_sz_info[0:1]:\n",
    "    print(f\"patient_id: {e[0]}\")\n",
    "    print(f\"file_name: {e[1]}\")\n",
    "\n",
    "    file_path = e[1]\n",
    "    df, data_info = ReadEdfFile(file_path)\n",
    "    file_sample_rate = data_info[\"sfreq\"]\n",
    "    file_meas_date = data_info[\"meas_date\"]\n",
    "    file_channel = data_info['ch_names']\n",
    "    relevant_channels = file_channel[0:2]\n",
    "    print(f\"freq: {file_sample_rate} meas: {file_meas_date} channels: {relevant_channels}\")\n",
    "    \n",
    "    insert_time_stamp(df, file_meas_date, file_sample_rate)\n",
    "    insert_class_col(df, e[2], file_sample_rate)\n",
    "\n",
    "    save_file_name = f\"patient_{e[0]}_date_{file_meas_date}.csv\"\n",
    "\n",
    "    #SAVE TO CSV\n",
    "\n",
    "    #LOGGING:\n",
    "    logging_info_txt(save_file_name, file_sample_rate, file_channel)\n",
    "\n",
    "    #Memory:\n",
    "    del df, data_info\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>CH-1</th>\n",
       "      <th>CH-2</th>\n",
       "      <th>CH-3</th>\n",
       "      <th>CH-4</th>\n",
       "      <th>CH-5</th>\n",
       "      <th>CH-6</th>\n",
       "      <th>CH-7</th>\n",
       "      <th>CH-8</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interictal</td>\n",
       "      <td>1.558447e+12</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.610537e-08</td>\n",
       "      <td>3.069114e-08</td>\n",
       "      <td>4.796582e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interictal</td>\n",
       "      <td>1.558447e+12</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8.610537e-08</td>\n",
       "      <td>3.069114e-08</td>\n",
       "      <td>4.796582e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interictal</td>\n",
       "      <td>1.558447e+12</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>8.610537e-08</td>\n",
       "      <td>3.069114e-08</td>\n",
       "      <td>4.796582e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interictal</td>\n",
       "      <td>1.558447e+12</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>8.610537e-08</td>\n",
       "      <td>3.069114e-08</td>\n",
       "      <td>4.796582e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interictal</td>\n",
       "      <td>1.558447e+12</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>8.610537e-08</td>\n",
       "      <td>3.069114e-08</td>\n",
       "      <td>4.796582e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class     timestamp      CH-1      CH-2      CH-3      CH-4      CH-5  \\\n",
       "0  Interictal  1.558447e+12  0.000017  0.000058  0.001171  0.001181 -0.000045   \n",
       "1  Interictal  1.558447e+12  0.000011  0.000053  0.001170  0.001180 -0.000051   \n",
       "2  Interictal  1.558447e+12  0.000036  0.000079  0.001169  0.001180 -0.000026   \n",
       "3  Interictal  1.558447e+12  0.000038  0.000079  0.001168  0.001179 -0.000025   \n",
       "4  Interictal  1.558447e+12  0.000064  0.000105  0.001167  0.001178  0.000003   \n",
       "\n",
       "       CH-6      CH-7      CH-8             x             y             z  \n",
       "0 -0.000051 -0.000065  0.000008  8.610537e-08  3.069114e-08  4.796582e-08  \n",
       "1 -0.000057 -0.000070  0.000003  8.610537e-08  3.069114e-08  4.796582e-08  \n",
       "2 -0.000032 -0.000045  0.000029  8.610537e-08  3.069114e-08  4.796582e-08  \n",
       "3 -0.000032 -0.000045  0.000029  8.610537e-08  3.069114e-08  4.796582e-08  \n",
       "4 -0.000005 -0.000017  0.000056  8.610537e-08  3.069114e-08  4.796582e-08  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skal ikke bruge nedenstÃ¥ende midlertidigt...\n",
    "def get_file_t_start_ms(filename):\n",
    "    str_t_start = re.match(r\".*Patient [0-9]+/(.*?)_\", filename)\n",
    "    if str_t_start:\n",
    "        str_t_start = str_t_start.group(1)\n",
    "        t_start = datetime.strptime(str_t_start, '%Y%m%d%H%M%S')\n",
    "        return t_start.timestamp() * 1000\n",
    "    else:\n",
    "        str_t_start = \"Time start is not present\"\n",
    "        return str_t_start\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 5, 22, 5, 29, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.fromtimestamp(1558495757000.0/1000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36ba892f7ad20bf7fdc5c3ef3188feda3b9d9c608c682b5345226fde4f33924b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
