{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.5.0\n",
      "Keras Version: 2.5.0\n",
      "\n",
      "Python 3.9.7 (default, Sep 16 2021, 23:53:23) \n",
      "[Clang 12.0.0 ]\n",
      "Pandas 1.3.1\n",
      "Scikit-Learn 0.24.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import mne\n",
    "import pathlib\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "import os\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "external_hardisk_data_path = os.path.abspath(os.sep) + \"./Volumes/Lacie/Database/\"\n",
    "\n",
    "train_path = external_hardisk_data_path + \"Single_channel_two_patient/train\"\n",
    "\n",
    "test_path = external_hardisk_data_path + \"Single_channel_two_patient/test\"\n",
    "\n",
    "test_df = pd.read_csv(\"single_patient_data/test_data\")\n",
    "\n",
    "resnet152_input_shape = (224, 224, 3)\n",
    "\n",
    "inceptionV3_input_shape = (299, 299, 3)\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-23 19:06:35.287163: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-10-23 19:06:35.287546: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "single_patient_model = tf.keras.models.load_model(\"h5_files/single.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_patient_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Interictal', 'Preictal_One', 'Preictal_Two', 'Seizure'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test windows png's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(\n",
    "  rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 4 classes.\n",
      "Found 0 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/speciale_01_01/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 879 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resnet_train_gen = generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    batch_size=batch_size, \n",
    "    target_size=resnet152_input_shape, \n",
    "    classes=list(labels), \n",
    "    shuffle=False)\n",
    "inception_train_gen = generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    batch_size=batch_size, \n",
    "    target_size=inceptionV3_input_shape, \n",
    "    classes=list(labels), \n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator_two_img():\n",
    "    while True:\n",
    "        X1i = inception_train_gen.next()\n",
    "        X2i = resnet_train_gen.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps = len(resnet_train_gen.filenames) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b84e05540a307b538244af4550d97e316ec86dc0712246a760046706883909fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('speciale_01_01': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
